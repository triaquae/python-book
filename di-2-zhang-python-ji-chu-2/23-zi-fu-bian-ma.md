本节重点：

* 让学生了解为什么会有编码
* 让学生了解字符编码的种类及其发展顺序
* py2和py3编码区别

## 引子

通过上一节讲的二进制的知识，大家已经知道计算机只认识二进制，生活中的数字要想让计算机理解就必须转换成二进制。十进制到二进制的转换只能解决计算机理解数字的问题，那么文字要怎么让计算机理解呢？

于是我们就选择了一种曲线救国的方式，既然数字可以转换成十进制，我们只要想办法把文字转换成数字，这样文字不就可以表示成二进制了么？

![](/assets/字符编码2.png)

> 可是文字应该怎么转换成数字呢？就是强制转换

我们自己强行约定了一个表，把文字和数字对应上，这张表就相当于翻译，我们可以拿着一个数字来对比对应表找到相应的文字，反之亦然。

## ASCII码

> 可以先让学生看图片，然后再介绍ascii码

假如我们就已经有这么一张表了![](/assets/ascii.jpg)

ASCII（American Standard Code for Information Interchange，美国信息交换标准代码）是基于[拉丁字母](http://baike.baidu.com/item/拉丁字母)的一套电脑编码系统，主要用于显示现代[英语](http://baike.baidu.com/item/英语/109997)和其他[西欧](http://baike.baidu.com/item/西欧)语言。它是现今最通用的单字节编码系统，并等同于[国际](http://baike.baidu.com/item/国际)标准ISO/IEC 646。

由于计算机是美国人发明的，因此，最早只有127个字母被编码到计算机里，也就是大小写英文字母、数字和一些符号，这个编码表被称为`ASCII`编码，比如大写字母 `A`的编码是`65`，小写字母 `z`的编码是`122`。后128个称为[扩展ASCII](http://baike.baidu.com/item/扩展ASCII)码。

那现在我们就知道了上面的字母符号和数字对应的表是早就存在的。那么根据现在有的一些十进制，我们就可以转换成二进制的编码串。

比如

```
一个空格对应的数字是0          翻译成二进制就是0（注意字符'0'和整数0是不同的）
一个对勾√对应的数字是251       翻译成二进制就是11111011
```

> **提问：假如我们要打印两个空格一个对勾 写作二进制就应该是 0011111011， 但是问题来了，我们怎么知道从哪儿到哪儿是一个字符呢？**
>
> 论断句的重要性与必要性：
>
> 上次在网上看到个新闻，讲是个小偷在上海被捕时高喊道：“我一定要当上海贼王！”

正是由于这些字符串长的长，短的短，写在一起让我们难以分清每一个字符的起止位置，所以聪明的人类就想出了一个解决办法，既然一共就这255个字符，那最长的也不过是11111111八位，不如我们就把所有的二进制都转换成8位的，不足的用0来替换。

这样一来，刚刚的两个空格一个对勾就写作000000000000000011111011，读取的时候只要每次读8个字符就能知道每个字符的二进制值啦。

在这里，每一位0或者1所占的空间单位为bit\(比特\)，这是计算机中最小的表示单位

每8个bit组成一个字节，这是计算机中最小的存储单位\(毕竟你是没有办法存储半个字符的\)orz～

> 要不要举例子说单位？就像我们形容长度会有厘米、分米、米之分，在计算机里也有自己的计量数据大小的单位
>
> 人民币的例子：给了你好多钱，假如没有万-十万

```
bit           位，计算机中最小的表示单位
8bit = 1bytes 字节，最小的存储单位，1bytes缩写为1B
1KB=1024B
1MB=1024KB
1GB=1024MB
1TB=1024GB
1PB=1024TB
1EB=1024PB
1ZB=1024EB
1YB=1024ZB
1BB=1024YB
```

> 提问：学完ascii码，作为一个英文程序员来说，基本圆满了。但是作为一个中国程序员，你是不是觉得少了点儿什么？（再给学生看一下ascii码表）

## GBK和**GB2312**

显然，对于我们来说能在计算机中显示中文字符是至关重要的，然而刚学习的**ASCII**表里连一个偏旁部首也没有。所以我们还需要一张关于中文和数字对应的关系表。之前我们已经看到了，一个字节只能最多表示256个字符，要处理中文显然一个字节是不够的，所以我们需要采用两个字节来表示，而且还不能和**ASCII**编码冲突，所以，中国制定了**GB2312**编码，用来把中文编进去。

> 你可以想得到的是，全世界有上百种语言，日本把日文编到**Shift\_JIS**里，韩国把韩文编到**Euc-kr**里，
>
> 各国有各国的标准，就会不可避免地出现冲突，结果就是，在多语言混合的文本中，显示出来会有乱码。

## **Unicode**

因此，**Unicode**应运而生。**Unicode**把所有语言都统一到一套编码里，这样就不会再有乱码问题了。

**Unicode**标准也在不断发展，但最常用的是用两个字节表示一个字符（如果要用到非常偏僻的字符，就需要**4**个字节）。现代[操作系统](http://lib.csdn.net/base/operatingsystem)和大多数编程语言都直接支持**Unicode**。

现在，捋一捋**ASCII**编码和**Unicode**编码的区别：

**ASCII**编码是**1**个字节，而**Unicode**编码通常是**2**个字节。

字母**A**用**ASCII**编码是十进制的**65**，二进制的**01000001**；

字符**0**用**ASCII**编码是十进制的**48**，二进制的**00110000**；

汉字“中”已经超出了**ASCII**编码的范围，用**Unicode**编码是十进制的**20013**，二进制的**01001110 00101101**。

你可以猜测，如果把**ASCII**编码的**A**用**Unicode**编码，只需要在前面补**0**就可以，因此，**A**的**Unicode**编码是**00000000 01000001**。

> 新的问题又出现了：如果统一成**Unicode**编码，乱码问题从此消失了。但是，如果你写的文本基本上全部是英文的话，用**Unicode**编码比**ASCII**编码需要多一倍的存储空间，在存储和传输上就十分不划算。

## **UTF-8**

所以，本着节约的精神，又出现了把**Unicode**编码转化为“可变长编码”的**UTF-8**编码。**UTF-8**编码把一个**Unicode**字符根据不同的数字大小编码成**1-6**个字节，常用的英文字母被编码成**1**个字节，汉字通常是**3**个字节，只有很生僻的字符才会被编码成**4-6**个字节。如果你要传输的文本包含大量英文字符，用**UTF-8**编码就能节省空间：

| 字符 | ASCII | Unicode | UTF-8 |
| :--- | :--- | :--- | :--- |
| A | 01000001 | 00000000 01000001 | 01000001 |
| 中 | x | 01001110 00101101 | 11100100 10111000 10101101 |

从上面的表格还可以发现，**UTF-8**编码有一个额外的好处，就是**ASCII**编码实际上可以被看成是**UTF-8**编码的一部分，所以，大量只支持**ASCII**编码的历史遗留软件可以在**UTF-8**编码下继续工作。

搞清楚了**ASCII**、**Unicode**和**UTF-8**的关系，我们就可以总结一下现在计算机系统通用的字符编码工作方式：

在计算机内存中，统一使用**Unicode**编码，当需要保存到硬盘或者需要传输的时候，就转换为**UTF-8**编码。

用记事本编辑的时候，从文件读取的**UTF-8**字符被转换为**Unicode**字符到内存里，编辑完成后，保存的时候再把**Unicode**转换为**UTF-8**保存到文件。

**文件存取编码转换图**

![](/assets/utf8&unicode文件存储.png)

## 常用编码介绍一览表

| 编码 | 制定时间 | 作用 | 所占字节数 |
| :--- | :--- | :--- | :--- |
| ASCII | 1967年 | 表示英语及西欧语言 | 8bit/1bytes |
| GB2312 | 1980年 | 国家简体中文字符集，兼容ASCII | 2bytes |
| Unicode | 1991年 | 国际标准组织统一标准字符集 | 2bytes |
| GBK | 1995年 | GB2312的扩展字符集，支持繁体字，兼容GB2312 | 2bytes |
| UTF-8 | 1992年 | 不定长编码 | 1-3bytes |



